<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
    <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
    <meta property="og:url" content="URL OF THE WEBSITE"/>
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>


    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Hang-Time HAR</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero" id="download">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Hang-Time HAR: A Benchmark Dataset for Basketball Activity
                        Recognition using Wrist-worn Inertial Sensors</h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
                Alexander Hoelzemann<strong>¹</strong>
                            <!-- <span class="author-block">
                              <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,
                              </span>-->
                        </span>
                        <span class="author-block">
                    Julia Lee Romero<strong>²</strong>
                  </span>
                        <span class="author-block">
                    Marius Bock<strong>¹</strong>
                  </span>
                        <span class="author-block">
                    Kristof Van Laerhoven<strong>¹</strong>
                  </span>
                        <span class="author-block">
                    Qin Lv<strong>²</strong>
                  </span>
                    </div>
                    <div class="is-size-5 publication-authors">
                        <span class="author-block">University of Siegen<strong>¹</strong> and University of Colorado Boulder<strong>²</strong></span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <span class="link-block">
                        <a href="https://doi.org/10.3390/s23135879" target="_blank"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                            <span class="link-block">
                    <a href="https://github.com/ahoelzemann/hangtime_har" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                            <!-- ArXiv abstract Link -->
                            <span class="link-block">
                  <a href="https://arxiv.org/pdf/2305.13124" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                            <span class="link-block">
                  <a href="https://doi.org/10.5281/zenodo.7920485" target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- Teaser video
<section class="hero teaser">
     <div class="container is-max-desktop">
    <div class="hero-body">
       <video poster="" id="tree" autoplay controls muted loop height="100%">
      
        <source src="static/videos/banner_video.mp4"
        type="video/mp4"
      </video>
        <img src="static/images/teaser_image.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          A scene and activities from the dataset:
          Offense play of player 12 (yellow) and player 6 (red),
          with player 12 dribbling the ball (1), (2) and then passing (3) it to player 6. Player 6 then performs a layup (4). Video frames 1-4 and the performed activities are highlighted in the time-series below.
        </h2
      </h2>
    </div>
  </div>
</section> End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        We present a benchmark dataset for evaluating physical human activity recognition methods from
                        wrist-worn sensors, for the specific setting of basketball training, drills, and games.
                        Basketball activities lend themselves well for measurement by wrist-worn inertial sensors, and
                        systems that are able to detect such sport-relevant activities could be used in applications
                        toward game analysis, guided training, and personal physical activity tracking. The dataset was
                        recorded for two teams from separate countries (USA and Germany) with a total of 24 players who
                        wore an inertial sensor on their wrist, during both repetitive basketball training sessions and
                        full games. Particular features of this dataset include an inherent variance through cultural
                        differences in game rules and styles as the data was recorded in two countries, as well as
                        different sport skill levels, since the participants were heterogeneous in terms of prior
                        basketball experience. We illustrate the dataset's features in several time-series analyses and
                        report on a baseline classification performance study with two state-of-the-art deep learning
                        architectures.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End paper abstract -->
<br>
<div class="header">
    <div class="wrap">
        <h2 class="title is-3">Results at a glance</h2>
    </div>
</div>
<!-- Image carousel -->
<section class="hero is-small">
    <div class="hero-body">
        <div class="container">
            <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/teaser_image.png" class="align-middle" alt="MY ALT TEXT"/>
                    <h2 class="subtitle has-text-centered">
                        <b>A scene</b> and activities from the dataset:
                        Offense play of player 12 (yellow) and player 6 (red),
                        with player 12 dribbling the ball (1), (2) and then passing (3) it to player 6.
                        Player 6 then performs a layup (4). Video frames 1-4 and the performed activities are
                        highlighted in the time-series below.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/fa_dribbling.png" alt="Feature Analysis"/>
                    <h2 class="subtitle has-text-centered">
                        Feature analysis of the class dribbling for players 4d70_eu, 10f0_eu, and 05d8_eu (experts)
                        and 2dd9_na, ce9d_na, and c6f3_na (novices). The plot consists of 4 columns. (1) Raw data as
                        recorded during the dedicated dribbling drill (approx. 7 min of data (Germany) and 5 min of data
                        (USA). The X-axis is represented in red, the Y-axis in green, and the Z-axis in blue color. (2)
                        Standard
                        deviation (diamond shape), median, interquartile q1 and q3 (rectangle shape) as well as upper
                        and
                        lower fences. (3) Fast Four Transformation. (4) Local maxima (prominence = 1.4) calculated
                        using the magnitude of the input signal (1), every red dot indicates a peak that is interpreted
                        as one
                        dribbling.
                    </h2>
                </div>
                <div class="item">
                    <!-- Your image here -->
                    <img src="static/images/dl_results.png" alt="Deep Learning"/>
                    <h2 class="subtitle has-text-centered">
                        Overall results of the deep learning experiments using a shallow DeepConvLSTM (blue)
                        and Attend-and-Discriminate architecture (orange). Both models were trained with a 1-layered
                        recurrent part with 1024 hidden units and a sliding window of 1 second with 50% overlap. The
                        left
                        plot (a) shows the per-class LOSO results obtained from training on the drill and warm-up data.
                        The
                        right plot (b) shows the per-class results predicting the game data when trained on the drill
                        and
                        warm-up data. All results are averages across 3 runs using a set of 3 random seeds. Both
                        architectures
                        suffer a significant loss in predictive performance when being applied to in-game data, i.e.,
                        data
                        recorded in an uncontrolled environment.
                    </h2>
                </div>
            </div>
        </div>
    </div>
</section>
<!-- End image carousel -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">The Dataset</h2>
                <div class="content has-text-justified">
                    <p>
                        The study protocol is divided into two parts. The first part is designed to collect
                        controlled data by having participants complete a sequence of predefined activities for
                        a defined period of time, while this first part is controlled, it also simulates real-world
                        basketball drills in practice sessions where players repeatedly practice a certain activity
                        (e.g., layups, shooting, dribbling, running). The second part is a basketball game between
                        two teams each with five players per team on the court, and extra players rotated into the
                        game. Video cameras were set up along the sidelines of the court in order to record each
                        participant’s activities for the labeling process.
                    </p>
                    <img src="static/images/court_diagram.png" alt="Study design"/>
                    <p>
                        Our <b>study design</b> used 24 subjects with 13 subjects living in
                        Germany and 11 subjects living in the United States of America.
                        In each study, the players simultaneously performed the drills and game while the entire
                        basketball court was monitored using two wide-angle cameras.
                        After the study, the camera footage was used for detailed annotation of all activity-relevant
                        data.
                    </p>
                    <img src="static/images/study_design_hangtime.png" alt="Class samples"/>
                    <p>Hang-Time HAR study protocol as executed at both locations. The German recording is
                        ~110 min and the American recording ~76 min long.
                    </p>
                    <h3 class="title is-3">Participants Meta Information</h3>
                    <img src="static/images/meta_info.png" alt="Meta Information"/>
                    <p>
                        Meta information as given through the study questionnaire by all participants, 13 from
                        Germany, Europe (eu) and 11 from USA, North America (na). A total of 3 participants were female
                        and 21 were male. The players were between 18 and 39 years old. Through self-assessment, in
                        which
                        participants were asked to evaluate their experience in basketball, 8 players responded with
                        novice
                        and 16 with expert. Two people were left-handed. Additional about the anthropomorphy of our
                        participants are excluded due to restrictions given by the Ethical Council of our university.
                    </p>
                    <h3 class="title is-3">Dataset Characteristics</h3>
                    <ul>
                        <li>Number of Participants: 24</li>
                        <li>Sampling Rate: 50 Hz</li>
                        <li>Sensors: Wrist-worn 3D Accelerometer <u><a href="https://shop.espruino.com/banglejs"
                                                                       target="_blank">(Bangle.js 1 Smart Watch)</a></u>
                        </li>
                        <li>Challenges: Imbalanced dataset that contains periodic, spontaneous and complex classes from
                            a controlled and uncontrolled recording environment.
                        </li>
                    </ul>
                    <p>
                        <b>Preprocessing:</b> We decided to keep the preprocessing on the raw data from the
                        smartwatches to a minimum, as these were already provided with a timestamp and in
                        the g unit. The smartwatch’s accelerometer samples’ timestamps contained slight (<2%)
                        deviations, so we adjusted the time-series by resampling to ensure that all data maintains
                        exact 50 Hz equidistant timestamps. Other common methods of preprocessing inertial data
                        for activity recognition, such as rescaling or normalization, were not applied.
                    </p>
                    <h3 class="title is-3">Usage</h3>
                    <p>
                        The dataset is saved in CSV format, with each player having an individual file. It can be easily
                        loaded using the
                        <u><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
                              target="_blank">read_csv</a></u> from the Pandas library,
                        which is commonly used for data manipulation and analysis in Python.
                        Once the dataset is loaded, the labels are stored in four different columns: Coarse, Locomotion,
                        Basketball, and In/Out.
                        The Coarse column separates the samples into different sessions, including warm-up, drills
                        (sitting, standing, walking, running, dribbling, penalty shots, two-point shots, and three-point
                        shots), game, and in/out.
                        The "game" label indicates when a game was played. The German study comprises two game sessions,
                        each lasting approximately 10 minutes, while the study conducted in the USA consists of one
                        session lasting approximately 22 minutes.
                        The Basketball and Locomotion tiers contain labels corresponding to different classes mentioned
                        in the table, as well as the "not_labeled" label. The "not_labeled" label is assigned when the
                        specific activity of a player couldn't
                        be observed in the ground truth video or between sessions. The In/Out tier is only relevant
                        during the game session and indicates whether a player is on the court or not.
                        <br><br>
                        <b>Combining Classes:</b> The layers provided in our dataset make it possible to extend
                        it with additional and more challenging classes. For example, shots can be distinguished
                        between penalty_shots, two_point_shots, and three_point_shots by taking into account the coarse
                        layer. The locomotion layer holds the information if the activity dribbling was performed
                        while the player was standing, walking, or running. Therefore, the class definitions in
                        aforementioned table only contain the basic classes and can be extended individuall, depending
                        on the
                        requirements of one’s project.
                    </p>
                    <h3 class="title is-3">Classes</h3>
                    <img src="static/images/class_description.png" alt="Meta Information"/>
                    <p>Detailed class description for every class included in the dataset. The dataset is multi-tier
                        labeled with 4 different layers (I) Coarse, (II) Locomotion, (III) Basketball, and (IV) In/Out.
                        The
                        coarse layer is not listed, since it is meant to indicate to which session an activity belongs.
                        Relevant
                        classes are classes 2–13. However, the classes in and out were not used in our validation.
                    </p>
                    <img src="static/images/class_samples.png" alt="Class samples"/>
                    <p>
                        <b>Exemplar time-series</b> data for the included activities. The examples shown for the
                        periodic
                        activities sitting , standing, walking, running, and dribbling contain 1200 samples (approx. 24
                        s). In
                        order to better represent the complex activities shot and layup as well as the micro-activities
                        pass and
                        rebound. Jumps are marked in classes where the activity occurs. Such short periods were
                        summarized
                        in the activity jumping.
                    </p>
                    <img src="static/images/class_distribution.png" alt="Class distribution"/>
                    <p>
                        <b>Class distribution</b> of the Hang-Time HAR dataset. Total number of samples per class are:
                        sitting : 383,622 (~2.1 h), standing: 368,189 (~2.0 h), walking: 1,885,644 (~10.5 h), running:
                        1,100,942 (~6.1 h), jumping: 96,857 (~0.53 h), dribbling: 878,514 (~4,8 h), shot: 149,040 (~0.82
                        h),
                        layup: 62,393 (~0.34 h), pass: 86,291 (~0.47 h), and rebound: 18,886 (~0.10 h). In total:
                        5,030,378 labeled samples or ~27.7 h of data
                    </p>

                    <b>Void Class:</b>
                    We originally included a void class for miscellaneous movements outside
                    of the primary labeled ones, such as drinking from a water bottle or tying shoes. These
                    were mostly performed during rest breaks. The samples annotated as void resulted in an
                    irrelevant small class, which could not be recognized by our classifier because they are most
                    often performed in conjunction with one of the locomotion classes. We ultimately decided
                    against including this void class, since it was very rare that players were not performing one
                    of the 10 classes of locomotion or basketball activities. However, the data that is not annotated
                    as one of the aforementioned classes are categorized as not_labeled. This class can be seen as
                    a very noisy but realistic void class that can be used by researchers whom focus on deeper
                    insights in the NULL-class problem
                </div>
            </div>
        </div>
    </div>
</section>
<br>
<section class="hero is-small">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Results</h2>
                <div class="content has-text-justified">
                    <p>
                        During our experiments, we are investigating how well our network generalizes in two regards:
                    <ul>
                        <li>Subject-independent generalization: As with almost any activity, basketball players tend
                            to have their own specific traits in performing each basketball-related activity. Within
                            these test cases, we investigate how well our network generalizes across subjects by
                            performing a LOSO cross-validation on the drill and warm-up data of all subjects.
                            During each validation step, the activities of a previously unseen subject are predicted,
                            and thus the experiments will determine how well our network generalizes across
                            subjects and whether subject-independent patterns can be learned by our architecture.
                        </li>
                        <li>Session-independent generalization: Data recorded during an
                            actual basketball game can heavily differ from "artificial" data recorded during the
                            drill and warm-up sessions, as subjects did not have to adhere to any (experimental)
                            protocol. Thus, the session-independent test cases investigate how well our network
                            predicts the same activities performed by already-seen subjects during an actual
                            game. Within these experiments, we train our network using data recorded by all
                            subjects during the drill and warm-up sessions and try to predict the game data of
                            said subjects. These type of experiments will give a sense of how well our network
                            is able to generalize specifically to real-world data and simulates the transition from
                            a controlled to an uncontrolled environment. The network learns player-specific
                            patterns from the warm-up and drill sessions and tries to classify the more dynamic
                            game subset.
                        </li>
                    </ul>

                    <img src="static/images/dl_results.png" alt="Deep Learning"/>

                    Overall results of the deep learning experiments using a shallow DeepConvLSTM (blue)
                    and Attend-and-Discriminate architecture (orange). Both models were trained with a 1-layered
                    recurrent part with 1024 hidden units and a sliding window of 1 second with 50% overlap. The left
                    plot (a) shows the per-class LOSO results obtained from training on the drill and warm-up data. The
                    right plot (b) shows the per-class results predicting the game data when trained on the drill and
                    warm-up data. All results are averages across 3 runs using a set of 3 random seeds. Both
                    architectures
                    suffer a significant loss in predictive performance when being applied to in-game data, i.e., data
                    recorded in an uncontrolled environment.

                    <br>
                    <br>
                    We refer to the <a href="https://www.mdpi.com/1424-8220/23/13/5879">paper</a> for a comprehensive dataset description and more detailed results.
                    <br>
                    <br>
                    <b>All important links</b> can be found at the <a href="#download">top</a> of the page.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>
<br>

<section class="section hero is-light" >
    <div class="container is-max-desktop content">
        <h2 class="title">Acknowledgments</h2>
        <p>
            We would like to thank the basketball players from the teams TuS Fellinghausen from Kreuztal, Germany, and the University of Colorado Boulder students for participating in our study.
        </p>
    </div>
</section>

<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@article{hoelzemannHangtimeHARBenchmark2023,
	title = {Hang-time HAR: A benchmark dataset for basketball activity recognition using wrist-worn inertial sensors},
	volume = {23},
	url = {https://doi.org/10.3390/s23135879},
	number = {13},
	journal = {Sensors},
	author = {Hoelzemann, Alexander and Romero, Julia L. and Bock, Marius and Van Laerhoven, Kristof and Lv, Qin},
	year = {2023},
}
</code></pre>
    </div>
</section>
<!--End BibTex citation -->

<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">

                    <p>
                        This page was built using the <a
                            href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic
                        Project Page Template</a>. <br> This website is licensed under a <a rel="license"
                                                                                            href="http://creativecommons.org/licenses/by-sa/4.0/"
                                                                                            target="_blank">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>

                </div>
            </div>
        </div>
    </div>
</footer>

<!-- Statcounter tracking code -->

<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>
